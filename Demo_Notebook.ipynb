{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, random_split, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import scipy.io\n",
    "from scipy.signal import spectrogram\n",
    "import os\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "import math\n",
    "from librosa.feature import melspectrogram\n",
    "from librosa.display import specshow\n",
    "import cv2\n",
    "import random\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo Image Data Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo Audio Data Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get spect_dataset\n",
    "class SpectDataset(Dataset):\n",
    "    def __init__(self, data_dir):\n",
    "        self.sample_list = []\n",
    "        \n",
    "        for filename in os.listdir(data_dir):\n",
    "            image = plt.imread(f'{data_dir}/{filename}')[:,:,0]\n",
    "            label = int(filename.split('-')[0][-1])\n",
    "            self.sample_list.append((label, torch.tensor(image), filename)) #class_label, data, filename\n",
    "                \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sample_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.sample_list[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data (spectrogram)\n",
    "trainset = SpectDataset('../Datasets/train/Spectrograms')\n",
    "valset = SpectDataset('../Datasets/val/Spectrograms')\n",
    "testset = SpectDataset('../Datasets/test/Spectrograms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Neural Network Model \n",
    "class AudioNetSpect(nn.Module):  #2D convolutions on spectrograms\n",
    "    def __init__(self, num_classes):\n",
    "        super(AudioNetSpect, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=7, stride=1, padding=0) #try making kernels larger, fewer layers, less maxp\n",
    "        self.batchnorm1 = nn.BatchNorm2d(16)\n",
    "        self.drop1 = nn.Dropout(p=0.5)\n",
    "        self.lrelu1 = nn.LeakyReLU()\n",
    "        self.max1 = nn.MaxPool2d(kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=0)\n",
    "        self.batchnorm2 = nn.BatchNorm2d(32)\n",
    "        self.drop2 = nn.Dropout(p=0.5)\n",
    "        self.lrelu2 = nn.LeakyReLU()\n",
    "        self.max2 = nn.MaxPool2d(kernel_size=3)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=0)\n",
    "        self.batchnorm3 = nn.BatchNorm2d(64)\n",
    "        self.fc1 = nn.Linear(64 * 8 * 13, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #print(x.shape)\n",
    "        x = self.conv1(x)\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.drop1(x)\n",
    "        x = self.lrelu1(x)\n",
    "        x = self.max1(x)\n",
    "        #print(x.shape)\n",
    "        x = self.conv2(x)\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.drop2(x)\n",
    "        x = self.lrelu2(x)\n",
    "        #print(x.shape)\n",
    "        x = self.max2(x)\n",
    "        #print(x.shape)\n",
    "        x = self.conv3(x)\n",
    "        x = self.batchnorm3(x)\n",
    "        #print(x.shape)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        #print(x.shape)\n",
    "        x = self.fc1(x)\n",
    "        #print(x.shape)\n",
    "        out = self.fc2(x)\n",
    "        #print(out.shape)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AudioNetSpect(\n",
       "  (conv1): Conv2d(1, 16, kernel_size=(7, 7), stride=(1, 1))\n",
       "  (batchnorm1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (drop1): Dropout(p=0.5, inplace=False)\n",
       "  (lrelu1): LeakyReLU(negative_slope=0.01)\n",
       "  (max1): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (batchnorm2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (drop2): Dropout(p=0.5, inplace=False)\n",
       "  (lrelu2): LeakyReLU(negative_slope=0.01)\n",
       "  (max2): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv3): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (batchnorm3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc1): Linear(in_features=6656, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=9, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model\n",
    "model = AudioNetSpect(num_classes=9)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders\n",
    "val_loader = DataLoader(dataset = valset,\n",
    "                      batch_size = 32,\n",
    "                      shuffle = False)\n",
    "\n",
    "train_loader = DataLoader(dataset = trainset,\n",
    "                      batch_size = 32,\n",
    "                      shuffle = True)\n",
    "\n",
    "test_loader = DataLoader(dataset = testset,\n",
    "                      batch_size = 32,\n",
    "                      shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Training Loss: 2.2212227980295816\n",
      "Val Loss: 4.0897000333213285 \n",
      "\n",
      "Epoch 6\n",
      "Training Loss: 0.9574459199456201\n",
      "Val Loss: 3.2537564352235715 \n",
      "\n",
      "Epoch 11\n",
      "Training Loss: 0.6474790497534517\n",
      "Val Loss: 2.046630311595357 \n",
      "\n",
      "Epoch 16\n",
      "Training Loss: 0.5200708242862121\n",
      "Val Loss: 2.2128447222968806 \n",
      "\n",
      "Epoch 21\n",
      "Training Loss: 0.4108680505575475\n",
      "Val Loss: 2.0192513517711475 \n",
      "\n",
      "Epoch 26\n",
      "Training Loss: 0.3892952429967514\n",
      "Val Loss: 1.7079246279419116 \n",
      "\n",
      "Epoch 31\n",
      "Training Loss: 0.808049185913515\n",
      "Val Loss: 3.92334936815314 \n",
      "\n",
      "Epoch 36\n",
      "Training Loss: 0.31203319824746123\n",
      "Val Loss: 1.6939864286181072 \n",
      "\n",
      "Epoch 41\n",
      "Training Loss: 0.31455468402608583\n",
      "Val Loss: 2.4970930934600206 \n",
      "\n",
      "Epoch 46\n",
      "Training Loss: 0.743855760689231\n",
      "Val Loss: 3.5665388351063365 \n",
      "\n",
      "Epoch 50\n",
      "Training Loss: 0.39336921026309324\n",
      "Val Loss: 3.502903089605515 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "best_val_loss = math.inf\n",
    "num_epochs = 50\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    tot_train_loss = 0\n",
    "    tot_train_samples = 0\n",
    "    \n",
    "    # Train Loop\n",
    "    model.train()\n",
    "    for i, (label, data, filename) in enumerate(train_loader):\n",
    "        data = data.type(torch.FloatTensor).cuda().unsqueeze(1)\n",
    "        label = label.long().cuda()\n",
    "        \n",
    "        optimizer.zero_grad() # clear gradients\n",
    "        outputs = model(data) # get outputs\n",
    "        train_loss = criterion(outputs, label) # get batch loss\n",
    "        tot_train_loss += train_loss.item() # add batch loss to total loss\n",
    "        tot_train_samples += data.shape[0] # add number of samples to total number of samples\n",
    "        train_loss.backward() # get gradients\n",
    "        optimizer.step() # update parameters\n",
    "    avg_train_loss = tot_train_loss / len(train_loader)\n",
    "    \n",
    "    # Eval Loop\n",
    "    tot_val_loss = 0\n",
    "    tot_val_samples = 0\n",
    "    pred_vec = []\n",
    "    label_vec = []\n",
    "    \n",
    "    model.eval()\n",
    "    for i, (label, data, filename) in enumerate(val_loader):\n",
    "        data = data.type(torch.FloatTensor).cuda().unsqueeze(1)\n",
    "        label = label.long().cuda()\n",
    "        \n",
    "        outputs = model(data) # get outputs\n",
    "        val_loss = criterion(outputs, label) # get batch loss\n",
    "        tot_val_loss += val_loss.item() # add batch loss to total loss\n",
    "        tot_val_samples += data.shape[0] # add number of samples to total number of samples\n",
    "        \n",
    "    avg_val_loss = tot_val_loss / len(val_loader)\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        torch.save(model.state_dict(), 'models/audio_net_spect.pt')\n",
    "        \n",
    "    # print losses every 5 epochs\n",
    "    if (epoch + 1) % 5 == 1 or (epoch + 1) == num_epochs:\n",
    "        print('Epoch {}'.format(epoch + 1))\n",
    "        print('Training Loss: {}'.format(avg_train_loss))\n",
    "        print('Val Loss: {} \\n'.format(avg_val_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.771919269354611\n",
      "recall: 0.6570119411137009\n",
      "f1: 0.678916937882043\n",
      "acc: 0.6757865937072504\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.54      0.68       170\n",
      "           1       0.41      0.91      0.57       162\n",
      "           2       0.67      0.77      0.72       202\n",
      "           3       0.93      0.54      0.68       179\n",
      "           4       0.63      0.64      0.64       203\n",
      "           5       0.66      0.77      0.71       184\n",
      "           6       0.81      0.55      0.65       119\n",
      "           7       0.93      0.70      0.80       204\n",
      "           8       0.95      0.51      0.67        39\n",
      "\n",
      "    accuracy                           0.68      1462\n",
      "   macro avg       0.77      0.66      0.68      1462\n",
      "weighted avg       0.75      0.68      0.68      1462\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test dataset\n",
    "# Load the data (spectrogram)\n",
    "trainset = SpectDataset('../Datasets/train/Spectrograms')\n",
    "valset = SpectDataset('../Datasets/val/Spectrograms')\n",
    "testset = SpectDataset('../Datasets/test/Spectrograms')\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(dataset = trainset,\n",
    "                      batch_size = 32,\n",
    "                      shuffle = True)\n",
    "\n",
    "val_loader = DataLoader(dataset = valset,\n",
    "                      batch_size = 32,\n",
    "                      shuffle = False)\n",
    "\n",
    "test_loader = DataLoader(dataset = testset,\n",
    "                      batch_size = 32,\n",
    "                      shuffle = False)\n",
    "\n",
    "predictions = []\n",
    "gt = []\n",
    "\n",
    "model = AudioNetSpect(num_classes=9)\n",
    "model.load_state_dict(torch.load('models/audio_net_spect.pt'))\n",
    "model.cuda()\n",
    "\n",
    "model.eval()\n",
    "\n",
    "\n",
    "\n",
    "predictions = []\n",
    "gt = []\n",
    "\n",
    "for i, (label, data, filename) in enumerate(test_loader):\n",
    "    data = data.type(torch.FloatTensor).cuda().unsqueeze(1)\n",
    "    label = label.long().cuda()\n",
    "\n",
    "    outputs = model(data) # get outputs\n",
    "    val_loss = criterion(outputs, label) # get batch loss\n",
    "    tot_val_loss += val_loss.item() # add batch loss to total loss\n",
    "    tot_val_samples += data.shape[0] # add number of samples to total number of samples\n",
    "\n",
    "    # Predictions\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    predictions += list(np.array(predicted.cpu()).ravel())\n",
    "    gt += list(np.array(label.cpu()).ravel())\n",
    "    \n",
    "# Print performance results\n",
    "print(f'precision: {precision_score(gt, predictions, average=\"macro\")}')\n",
    "print(f'recall: {recall_score(gt, predictions, average=\"macro\")}')\n",
    "print(f'f1: {f1_score(gt, predictions, average=\"macro\")}')\n",
    "print(f'acc: {accuracy_score(gt, predictions)}')\n",
    "print()\n",
    "print(classification_report(gt, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate on NoisyRawSpectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.7655531621657431\n",
      "recall: 0.6308606210189561\n",
      "f1: 0.6558567668955364\n",
      "acc: 0.6436388508891929\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.49      0.65       170\n",
      "           1       0.36      0.96      0.52       162\n",
      "           2       0.72      0.67      0.70       202\n",
      "           3       0.85      0.58      0.69       179\n",
      "           4       0.62      0.61      0.62       203\n",
      "           5       0.67      0.74      0.70       184\n",
      "           6       0.85      0.52      0.65       119\n",
      "           7       0.91      0.58      0.71       204\n",
      "           8       0.95      0.51      0.67        39\n",
      "\n",
      "    accuracy                           0.64      1462\n",
      "   macro avg       0.77      0.63      0.66      1462\n",
      "weighted avg       0.75      0.64      0.66      1462\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test dataset\n",
    "# Load the data (spectrogram)\n",
    "trainset = SpectDataset('../Datasets/train/NoisyRawSpectrograms')\n",
    "valset = SpectDataset('../Datasets/val/NoisyRawSpectrograms')\n",
    "testset = SpectDataset('../Datasets/test/NoisyRawSpectrograms')\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(dataset = trainset,\n",
    "                      batch_size = 32,\n",
    "                      shuffle = True)\n",
    "\n",
    "val_loader = DataLoader(dataset = valset,\n",
    "                      batch_size = 32,\n",
    "                      shuffle = False)\n",
    "\n",
    "test_loader = DataLoader(dataset = testset,\n",
    "                      batch_size = 32,\n",
    "                      shuffle = False)\n",
    "\n",
    "predictions = []\n",
    "gt = []\n",
    "\n",
    "model = AudioNetSpect(num_classes=9)\n",
    "model.load_state_dict(torch.load('models/audio_net_spect.pt'))\n",
    "model.cuda()\n",
    "\n",
    "model.eval()\n",
    "\n",
    "\n",
    "\n",
    "predictions = []\n",
    "gt = []\n",
    "\n",
    "for i, (label, data, filename) in enumerate(test_loader):\n",
    "    data = data.type(torch.FloatTensor).cuda().unsqueeze(1)\n",
    "    label = label.long().cuda()\n",
    "\n",
    "    outputs = model(data) # get outputs\n",
    "    val_loss = criterion(outputs, label) # get batch loss\n",
    "    tot_val_loss += val_loss.item() # add batch loss to total loss\n",
    "    tot_val_samples += data.shape[0] # add number of samples to total number of samples\n",
    "\n",
    "    # Predictions\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    predictions += list(np.array(predicted.cpu()).ravel())\n",
    "    gt += list(np.array(label.cpu()).ravel())\n",
    "    \n",
    "# Print performance results\n",
    "print(f'precision: {precision_score(gt, predictions, average=\"macro\")}')\n",
    "print(f'recall: {recall_score(gt, predictions, average=\"macro\")}')\n",
    "print(f'f1: {f1_score(gt, predictions, average=\"macro\")}')\n",
    "print(f'acc: {accuracy_score(gt, predictions)}')\n",
    "print()\n",
    "print(classification_report(gt, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate on NoisySpectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.4258816994268162\n",
      "recall: 0.21544657452650245\n",
      "f1: 0.14958378745517759\n",
      "acc: 0.20588235294117646\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.01      0.01       170\n",
      "           1       0.14      1.00      0.25       162\n",
      "           2       0.11      0.03      0.05       202\n",
      "           3       0.47      0.08      0.13       179\n",
      "           4       0.57      0.23      0.32       203\n",
      "           5       1.00      0.01      0.01       184\n",
      "           6       0.55      0.59      0.57       119\n",
      "           7       0.00      0.00      0.00       204\n",
      "           8       0.00      0.00      0.00        39\n",
      "\n",
      "    accuracy                           0.21      1462\n",
      "   macro avg       0.43      0.22      0.15      1462\n",
      "weighted avg       0.45      0.21      0.14      1462\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmian\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jmian\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test dataset\n",
    "# Load the data (spectrogram)\n",
    "trainset = SpectDataset('../Datasets/train/NoisySpectrograms')\n",
    "valset = SpectDataset('../Datasets/val/NoisySpectrograms')\n",
    "testset = SpectDataset('../Datasets/test/NoisySpectrograms')\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(dataset = trainset,\n",
    "                      batch_size = 32,\n",
    "                      shuffle = True)\n",
    "\n",
    "val_loader = DataLoader(dataset = valset,\n",
    "                      batch_size = 32,\n",
    "                      shuffle = False)\n",
    "\n",
    "test_loader = DataLoader(dataset = testset,\n",
    "                      batch_size = 32,\n",
    "                      shuffle = False)\n",
    "\n",
    "predictions = []\n",
    "gt = []\n",
    "\n",
    "model = AudioNetSpect(num_classes=9)\n",
    "model.load_state_dict(torch.load('models/audio_net_spect.pt'))\n",
    "model.cuda()\n",
    "\n",
    "model.eval()\n",
    "\n",
    "\n",
    "\n",
    "predictions = []\n",
    "gt = []\n",
    "\n",
    "for i, (label, data, filename) in enumerate(test_loader):\n",
    "    data = data.type(torch.FloatTensor).cuda().unsqueeze(1)\n",
    "    label = label.long().cuda()\n",
    "\n",
    "    outputs = model(data) # get outputs\n",
    "    val_loss = criterion(outputs, label) # get batch loss\n",
    "    tot_val_loss += val_loss.item() # add batch loss to total loss\n",
    "    tot_val_samples += data.shape[0] # add number of samples to total number of samples\n",
    "\n",
    "    # Predictions\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    predictions += list(np.array(predicted.cpu()).ravel())\n",
    "    gt += list(np.array(label.cpu()).ravel())\n",
    "    \n",
    "# Print performance results\n",
    "print(f'precision: {precision_score(gt, predictions, average=\"macro\")}')\n",
    "print(f'recall: {recall_score(gt, predictions, average=\"macro\")}')\n",
    "print(f'f1: {f1_score(gt, predictions, average=\"macro\")}')\n",
    "print(f'acc: {accuracy_score(gt, predictions)}')\n",
    "print()\n",
    "print(classification_report(gt, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on NoisyRawSpectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Training Loss: 2.2756702683974\n",
      "Val Loss: 2.118216477010561 \n",
      "\n",
      "Epoch 6\n",
      "Training Loss: 1.0858948589235111\n",
      "Val Loss: 3.3936241934804814 \n",
      "\n",
      "Epoch 11\n",
      "Training Loss: 0.8385121470344239\n",
      "Val Loss: 1.6606252044439316 \n",
      "\n",
      "Epoch 16\n",
      "Training Loss: 0.6158556057059247\n",
      "Val Loss: 1.7358367339424465 \n",
      "\n",
      "Epoch 21\n",
      "Training Loss: 0.4884058096702548\n",
      "Val Loss: 1.1876676076132318 \n",
      "\n",
      "Epoch 26\n",
      "Training Loss: 0.49340139564710495\n",
      "Val Loss: 1.5647293347865343 \n",
      "\n",
      "Epoch 31\n",
      "Training Loss: 0.422803268160509\n",
      "Val Loss: 1.6660945479474638 \n",
      "\n",
      "Epoch 36\n",
      "Training Loss: 0.29783680719201977\n",
      "Val Loss: 1.645279102148893 \n",
      "\n",
      "Epoch 41\n",
      "Training Loss: 0.3664660068006133\n",
      "Val Loss: 1.5731258560781893 \n",
      "\n",
      "Epoch 46\n",
      "Training Loss: 0.5993773919948633\n",
      "Val Loss: 1.0202833141969598 \n",
      "\n",
      "Epoch 50\n",
      "Training Loss: 0.43868957951232984\n",
      "Val Loss: 1.93101949694202 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the data (spectrogram)\n",
    "trainset = SpectDataset('../Datasets/train/NoisyRawSpectrograms')\n",
    "valset = SpectDataset('../Datasets/val/NoisyRawSpectrograms')\n",
    "testset = SpectDataset('../Datasets/test/NoisyRawSpectrograms')\n",
    "\n",
    "# Load model\n",
    "model = AudioNetSpect(num_classes=9)\n",
    "model.cuda()\n",
    "\n",
    "# Get loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "# Create data loaders\n",
    "val_loader = DataLoader(dataset = valset,\n",
    "                      batch_size = 32,\n",
    "                      shuffle = False)\n",
    "\n",
    "train_loader = DataLoader(dataset = trainset,\n",
    "                      batch_size = 32,\n",
    "                      shuffle = True)\n",
    "\n",
    "test_loader = DataLoader(dataset = testset,\n",
    "                      batch_size = 32,\n",
    "                      shuffle = True)\n",
    "\n",
    "# Train the model\n",
    "best_val_loss = math.inf\n",
    "num_epochs = 50\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    tot_train_loss = 0\n",
    "    tot_train_samples = 0\n",
    "    \n",
    "    # Train Loop\n",
    "    model.train()\n",
    "    for i, (label, data, filename) in enumerate(train_loader):\n",
    "        data = data.type(torch.FloatTensor).cuda().unsqueeze(1)\n",
    "        label = label.long().cuda()\n",
    "        \n",
    "        optimizer.zero_grad() # clear gradients\n",
    "        outputs = model(data) # get outputs\n",
    "        train_loss = criterion(outputs, label) # get batch loss\n",
    "        tot_train_loss += train_loss.item() # add batch loss to total loss\n",
    "        tot_train_samples += data.shape[0] # add number of samples to total number of samples\n",
    "        train_loss.backward() # get gradients\n",
    "        optimizer.step() # update parameters\n",
    "    avg_train_loss = tot_train_loss / len(train_loader)\n",
    "    \n",
    "    # Eval Loop\n",
    "    tot_val_loss = 0\n",
    "    tot_val_samples = 0\n",
    "    pred_vec = []\n",
    "    label_vec = []\n",
    "    \n",
    "    model.eval()\n",
    "    for i, (label, data, filename) in enumerate(val_loader):\n",
    "        data = data.type(torch.FloatTensor).cuda().unsqueeze(1)\n",
    "        label = label.long().cuda()\n",
    "        \n",
    "        outputs = model(data) # get outputs\n",
    "        val_loss = criterion(outputs, label) # get batch loss\n",
    "        tot_val_loss += val_loss.item() # add batch loss to total loss\n",
    "        tot_val_samples += data.shape[0] # add number of samples to total number of samples\n",
    "\n",
    "    avg_val_loss = tot_val_loss / len(val_loader)\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        torch.save(model.state_dict(), 'models/audio_net_noisy_raw_spect.pt')\n",
    "        \n",
    "    # print losses every 5 epochs\n",
    "    if (epoch + 1) % 5 == 1 or (epoch + 1) == num_epochs:\n",
    "        print('Epoch {}'.format(epoch + 1))\n",
    "        print('Training Loss: {}'.format(avg_train_loss))\n",
    "        print('Val Loss: {} \\n'.format(avg_val_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Noisy Raw Spect Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate on Raw Spectrograms\n",
      "precision: 0.7552627526947132\n",
      "recall: 0.6632216974235827\n",
      "f1: 0.6769958631058497\n",
      "acc: 0.6607387140902873\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.56      0.70       170\n",
      "           1       0.41      0.93      0.57       162\n",
      "           2       0.78      0.66      0.72       202\n",
      "           3       0.92      0.43      0.59       179\n",
      "           4       0.65      0.55      0.60       203\n",
      "           5       0.68      0.71      0.69       184\n",
      "           6       0.76      0.57      0.65       119\n",
      "           7       0.68      0.85      0.75       204\n",
      "           8       1.00      0.72      0.84        39\n",
      "\n",
      "    accuracy                           0.66      1462\n",
      "   macro avg       0.76      0.66      0.68      1462\n",
      "weighted avg       0.73      0.66      0.66      1462\n",
      "\n",
      "\n",
      "Evaluate on Noisy Raw Spectrograms\n",
      "precision: 0.7617444365724185\n",
      "recall: 0.6477097388222236\n",
      "f1: 0.6660113190078233\n",
      "acc: 0.6450068399452804\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.54      0.69       170\n",
      "           1       0.37      0.96      0.53       162\n",
      "           2       0.79      0.59      0.68       202\n",
      "           3       0.93      0.43      0.59       179\n",
      "           4       0.63      0.55      0.59       203\n",
      "           5       0.69      0.72      0.71       184\n",
      "           6       0.77      0.55      0.64       119\n",
      "           7       0.71      0.79      0.75       204\n",
      "           8       1.00      0.69      0.82        39\n",
      "\n",
      "    accuracy                           0.65      1462\n",
      "   macro avg       0.76      0.65      0.67      1462\n",
      "weighted avg       0.74      0.65      0.65      1462\n",
      "\n",
      "\n",
      "Evaluate on Noisy Spectrograms\n",
      "precision: 0.42754584008804464\n",
      "recall: 0.1254574820012604\n",
      "f1: 0.050238727689674155\n",
      "acc: 0.1265389876880985\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.02      0.03       170\n",
      "           1       0.12      1.00      0.21       162\n",
      "           2       0.80      0.02      0.04       202\n",
      "           3       0.47      0.05      0.09       179\n",
      "           4       0.75      0.01      0.03       203\n",
      "           5       0.00      0.00      0.00       184\n",
      "           6       0.67      0.02      0.03       119\n",
      "           7       0.04      0.01      0.02       204\n",
      "           8       0.00      0.00      0.00        39\n",
      "\n",
      "    accuracy                           0.13      1462\n",
      "   macro avg       0.43      0.13      0.05      1462\n",
      "weighted avg       0.46      0.13      0.05      1462\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "################################################ EVALUATE ON RAW SPECT ##############################\n",
    "# Load the data (spectrogram)\n",
    "trainset = SpectDataset('../Datasets/train/Spectrograms')\n",
    "valset = SpectDataset('../Datasets/val/Spectrograms')\n",
    "testset = SpectDataset('../Datasets/test/Spectrograms')\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(dataset = trainset,\n",
    "                      batch_size = 32,\n",
    "                      shuffle = True)\n",
    "\n",
    "val_loader = DataLoader(dataset = valset,\n",
    "                      batch_size = 32,\n",
    "                      shuffle = False)\n",
    "\n",
    "test_loader = DataLoader(dataset = testset,\n",
    "                      batch_size = 32,\n",
    "                      shuffle = False)\n",
    "\n",
    "predictions = []\n",
    "gt = []\n",
    "\n",
    "model = AudioNetSpect(num_classes=9)\n",
    "model.load_state_dict(torch.load('models/audio_net_noisy_raw_spect.pt'))\n",
    "model.cuda()\n",
    "\n",
    "model.eval()\n",
    "\n",
    "\n",
    "\n",
    "predictions = []\n",
    "gt = []\n",
    "\n",
    "for i, (label, data, filename) in enumerate(test_loader):\n",
    "    data = data.type(torch.FloatTensor).cuda().unsqueeze(1)\n",
    "    label = label.long().cuda()\n",
    "\n",
    "    outputs = model(data) # get outputs\n",
    "    val_loss = criterion(outputs, label) # get batch loss\n",
    "    tot_val_loss += val_loss.item() # add batch loss to total loss\n",
    "    tot_val_samples += data.shape[0] # add number of samples to total number of samples\n",
    "\n",
    "    # Predictions\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    predictions += list(np.array(predicted.cpu()).ravel())\n",
    "    gt += list(np.array(label.cpu()).ravel())\n",
    "    \n",
    "# Print performance results\n",
    "print('Evaluate on Raw Spectrograms')\n",
    "print(f'precision: {precision_score(gt, predictions, average=\"macro\")}')\n",
    "print(f'recall: {recall_score(gt, predictions, average=\"macro\")}')\n",
    "print(f'f1: {f1_score(gt, predictions, average=\"macro\")}')\n",
    "print(f'acc: {accuracy_score(gt, predictions)}')\n",
    "print()\n",
    "print(classification_report(gt, predictions))\n",
    "print()\n",
    "\n",
    "################################################ EVALUATE ON NOISY RAW SPECT ##############################\n",
    "# Evaluate the model on the test dataset\n",
    "# Load the data (spectrogram)\n",
    "trainset = SpectDataset('../Datasets/train/NoisyRawSpectrograms')\n",
    "valset = SpectDataset('../Datasets/val/NoisyRawSpectrograms')\n",
    "testset = SpectDataset('../Datasets/test/NoisyRawSpectrograms')\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(dataset = trainset,\n",
    "                      batch_size = 32,\n",
    "                      shuffle = True)\n",
    "\n",
    "val_loader = DataLoader(dataset = valset,\n",
    "                      batch_size = 32,\n",
    "                      shuffle = False)\n",
    "\n",
    "test_loader = DataLoader(dataset = testset,\n",
    "                      batch_size = 32,\n",
    "                      shuffle = False)\n",
    "\n",
    "predictions = []\n",
    "gt = []\n",
    "\n",
    "model = AudioNetSpect(num_classes=9)\n",
    "model.load_state_dict(torch.load('models/audio_net_noisy_raw_spect.pt'))\n",
    "model.cuda()\n",
    "\n",
    "model.eval()\n",
    "\n",
    "\n",
    "\n",
    "predictions = []\n",
    "gt = []\n",
    "\n",
    "for i, (label, data, filename) in enumerate(test_loader):\n",
    "    data = data.type(torch.FloatTensor).cuda().unsqueeze(1)\n",
    "    label = label.long().cuda()\n",
    "\n",
    "    outputs = model(data) # get outputs\n",
    "    val_loss = criterion(outputs, label) # get batch loss\n",
    "    tot_val_loss += val_loss.item() # add batch loss to total loss\n",
    "    tot_val_samples += data.shape[0] # add number of samples to total number of samples\n",
    "\n",
    "    # Predictions\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    predictions += list(np.array(predicted.cpu()).ravel())\n",
    "    gt += list(np.array(label.cpu()).ravel())\n",
    "    \n",
    "# Print performance results\n",
    "print('Evaluate on Noisy Raw Spectrograms')\n",
    "print(f'precision: {precision_score(gt, predictions, average=\"macro\")}')\n",
    "print(f'recall: {recall_score(gt, predictions, average=\"macro\")}')\n",
    "print(f'f1: {f1_score(gt, predictions, average=\"macro\")}')\n",
    "print(f'acc: {accuracy_score(gt, predictions)}')\n",
    "print()\n",
    "print(classification_report(gt, predictions))\n",
    "print()\n",
    "\n",
    "################################################ EVALUATE ON NOISY SPECT ##############################\n",
    "# Evaluate the model on the test dataset\n",
    "# Load the data (spectrogram)\n",
    "trainset = SpectDataset('../Datasets/train/NoisySpectrograms')\n",
    "valset = SpectDataset('../Datasets/val/NoisySpectrograms')\n",
    "testset = SpectDataset('../Datasets/test/NoisySpectrograms')\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(dataset = trainset,\n",
    "                      batch_size = 32,\n",
    "                      shuffle = True)\n",
    "\n",
    "val_loader = DataLoader(dataset = valset,\n",
    "                      batch_size = 32,\n",
    "                      shuffle = False)\n",
    "\n",
    "test_loader = DataLoader(dataset = testset,\n",
    "                      batch_size = 32,\n",
    "                      shuffle = False)\n",
    "\n",
    "predictions = []\n",
    "gt = []\n",
    "\n",
    "model = AudioNetSpect(num_classes=9)\n",
    "model.load_state_dict(torch.load('models/audio_net_noisy_raw_spect.pt'))\n",
    "model.cuda()\n",
    "\n",
    "model.eval()\n",
    "\n",
    "\n",
    "\n",
    "predictions = []\n",
    "gt = []\n",
    "\n",
    "for i, (label, data, filename) in enumerate(test_loader):\n",
    "    data = data.type(torch.FloatTensor).cuda().unsqueeze(1)\n",
    "    label = label.long().cuda()\n",
    "\n",
    "    outputs = model(data) # get outputs\n",
    "    val_loss = criterion(outputs, label) # get batch loss\n",
    "    tot_val_loss += val_loss.item() # add batch loss to total loss\n",
    "    tot_val_samples += data.shape[0] # add number of samples to total number of samples\n",
    "\n",
    "    # Predictions\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    predictions += list(np.array(predicted.cpu()).ravel())\n",
    "    gt += list(np.array(label.cpu()).ravel())\n",
    "    \n",
    "# Print performance results\n",
    "print('Evaluate on Noisy Spectrograms')\n",
    "print(f'precision: {precision_score(gt, predictions, average=\"macro\")}')\n",
    "print(f'recall: {recall_score(gt, predictions, average=\"macro\")}')\n",
    "print(f'f1: {f1_score(gt, predictions, average=\"macro\")}')\n",
    "print(f'acc: {accuracy_score(gt, predictions)}')\n",
    "print()\n",
    "print(classification_report(gt, predictions))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on Noisy Spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Training Loss: 2.4051252387572024\n",
      "Val Loss: 1.8614115818687107 \n",
      "\n",
      "Epoch 6\n",
      "Training Loss: 1.1810212649297023\n",
      "Val Loss: 1.5157391312329664 \n",
      "\n",
      "Epoch 11\n",
      "Training Loss: 0.9479295735017977\n",
      "Val Loss: 1.4484348063883574 \n",
      "\n",
      "Epoch 16\n",
      "Training Loss: 0.6555044700702032\n",
      "Val Loss: 1.3646319738548736 \n",
      "\n",
      "Epoch 21\n",
      "Training Loss: 0.6922377730030954\n",
      "Val Loss: 1.2742882681929546 \n",
      "\n",
      "Epoch 26\n",
      "Training Loss: 0.530817932786717\n",
      "Val Loss: 1.1741504137930663 \n",
      "\n",
      "Epoch 31\n",
      "Training Loss: 0.3877294404783111\n",
      "Val Loss: 1.1015700665505037 \n",
      "\n",
      "Epoch 36\n",
      "Training Loss: 0.3456068868222444\n",
      "Val Loss: 1.1038007937047793 \n",
      "\n",
      "Epoch 41\n",
      "Training Loss: 0.28511003691001213\n",
      "Val Loss: 1.129645327511041 \n",
      "\n",
      "Epoch 46\n",
      "Training Loss: 0.398265616428377\n",
      "Val Loss: 1.3364705268455588 \n",
      "\n",
      "Epoch 50\n",
      "Training Loss: 0.22197384241468976\n",
      "Val Loss: 1.1470362051673557 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the data (spectrogram)\n",
    "trainset = SpectDataset('../Datasets/train/NoisySpectrograms')\n",
    "valset = SpectDataset('../Datasets/val/NoisySpectrograms')\n",
    "testset = SpectDataset('../Datasets/test/NoisySpectrograms')\n",
    "\n",
    "# Load model\n",
    "model = AudioNetSpect(num_classes=9)\n",
    "model.cuda()\n",
    "\n",
    "# Get loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "# Create data loaders\n",
    "val_loader = DataLoader(dataset = valset,\n",
    "                      batch_size = 32,\n",
    "                      shuffle = False)\n",
    "\n",
    "train_loader = DataLoader(dataset = trainset,\n",
    "                      batch_size = 32,\n",
    "                      shuffle = True)\n",
    "\n",
    "test_loader = DataLoader(dataset = testset,\n",
    "                      batch_size = 32,\n",
    "                      shuffle = True)\n",
    "\n",
    "# Train the model\n",
    "best_val_loss = math.inf\n",
    "num_epochs = 50\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    tot_train_loss = 0\n",
    "    tot_train_samples = 0\n",
    "    \n",
    "    # Train Loop\n",
    "    model.train()\n",
    "    for i, (label, data, filename) in enumerate(train_loader):\n",
    "        data = data.type(torch.FloatTensor).cuda().unsqueeze(1)\n",
    "        label = label.long().cuda()\n",
    "        \n",
    "        optimizer.zero_grad() # clear gradients\n",
    "        outputs = model(data) # get outputs\n",
    "        train_loss = criterion(outputs, label) # get batch loss\n",
    "        tot_train_loss += train_loss.item() # add batch loss to total loss\n",
    "        tot_train_samples += data.shape[0] # add number of samples to total number of samples\n",
    "        train_loss.backward() # get gradients\n",
    "        optimizer.step() # update parameters\n",
    "    avg_train_loss = tot_train_loss / len(train_loader)\n",
    "    \n",
    "    # Eval Loop\n",
    "    tot_val_loss = 0\n",
    "    tot_val_samples = 0\n",
    "    pred_vec = []\n",
    "    label_vec = []\n",
    "    \n",
    "    model.eval()\n",
    "    for i, (label, data, filename) in enumerate(val_loader):\n",
    "        data = data.type(torch.FloatTensor).cuda().unsqueeze(1)\n",
    "        label = label.long().cuda()\n",
    "        \n",
    "        outputs = model(data) # get outputs\n",
    "        val_loss = criterion(outputs, label) # get batch loss\n",
    "        tot_val_loss += val_loss.item() # add batch loss to total loss\n",
    "        tot_val_samples += data.shape[0] # add number of samples to total number of samples\n",
    "\n",
    "    avg_val_loss = tot_val_loss / len(val_loader)\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        torch.save(model.state_dict(), 'models/audio_net_noisy_spect.pt')\n",
    "        \n",
    "    # print losses every 5 epochs\n",
    "    if (epoch + 1) % 5 == 1 or (epoch + 1) == num_epochs:\n",
    "        print('Epoch {}'.format(epoch + 1))\n",
    "        print('Training Loss: {}'.format(avg_train_loss))\n",
    "        print('Val Loss: {} \\n'.format(avg_val_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Noisy Spect Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate on Raw Spectrograms\n",
      "precision: 0.696816511488185\n",
      "recall: 0.6366347036662606\n",
      "f1: 0.6423070194735482\n",
      "acc: 0.6272229822161423\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.62      0.73       170\n",
      "           1       0.79      0.73      0.76       162\n",
      "           2       0.63      0.54      0.58       202\n",
      "           3       0.73      0.50      0.60       179\n",
      "           4       0.80      0.38      0.52       203\n",
      "           5       0.49      0.77      0.60       184\n",
      "           6       0.53      0.71      0.61       119\n",
      "           7       0.51      0.81      0.62       204\n",
      "           8       0.90      0.67      0.76        39\n",
      "\n",
      "    accuracy                           0.63      1462\n",
      "   macro avg       0.70      0.64      0.64      1462\n",
      "weighted avg       0.68      0.63      0.63      1462\n",
      "\n",
      "\n",
      "Evaluate on Noisy Raw Spectrograms\n",
      "precision: 0.6943385086700133\n",
      "recall: 0.6353098426709216\n",
      "f1: 0.6413703269362652\n",
      "acc: 0.6258549931600548\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.62      0.73       170\n",
      "           1       0.78      0.70      0.74       162\n",
      "           2       0.61      0.54      0.58       202\n",
      "           3       0.73      0.51      0.60       179\n",
      "           4       0.79      0.38      0.51       203\n",
      "           5       0.48      0.77      0.59       184\n",
      "           6       0.56      0.72      0.63       119\n",
      "           7       0.51      0.81      0.63       204\n",
      "           8       0.90      0.67      0.76        39\n",
      "\n",
      "    accuracy                           0.63      1462\n",
      "   macro avg       0.69      0.64      0.64      1462\n",
      "weighted avg       0.67      0.63      0.62      1462\n",
      "\n",
      "\n",
      "Evaluate on Noisy Spectrograms\n",
      "precision: 0.7079824984466647\n",
      "recall: 0.6654847829494599\n",
      "f1: 0.6611239795762446\n",
      "acc: 0.652530779753762\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.62      0.73       170\n",
      "           1       0.70      0.81      0.75       162\n",
      "           2       0.60      0.61      0.61       202\n",
      "           3       0.86      0.53      0.66       179\n",
      "           4       0.73      0.32      0.44       203\n",
      "           5       0.63      0.76      0.68       184\n",
      "           6       0.45      0.76      0.57       119\n",
      "           7       0.59      0.87      0.70       204\n",
      "           8       0.93      0.72      0.81        39\n",
      "\n",
      "    accuracy                           0.65      1462\n",
      "   macro avg       0.71      0.67      0.66      1462\n",
      "weighted avg       0.69      0.65      0.65      1462\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "################################################ EVALUATE ON RAW SPECT ##############################\n",
    "# Load the data (spectrogram)\n",
    "trainset = SpectDataset('../Datasets/train/Spectrograms')\n",
    "valset = SpectDataset('../Datasets/val/Spectrograms')\n",
    "testset = SpectDataset('../Datasets/test/Spectrograms')\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(dataset = trainset,\n",
    "                      batch_size = 32,\n",
    "                      shuffle = True)\n",
    "\n",
    "val_loader = DataLoader(dataset = valset,\n",
    "                      batch_size = 32,\n",
    "                      shuffle = False)\n",
    "\n",
    "test_loader = DataLoader(dataset = testset,\n",
    "                      batch_size = 32,\n",
    "                      shuffle = False)\n",
    "\n",
    "predictions = []\n",
    "gt = []\n",
    "\n",
    "model = AudioNetSpect(num_classes=9)\n",
    "model.load_state_dict(torch.load('models/audio_net_noisy_spect.pt'))\n",
    "model.cuda()\n",
    "\n",
    "model.eval()\n",
    "\n",
    "\n",
    "\n",
    "predictions = []\n",
    "gt = []\n",
    "\n",
    "for i, (label, data, filename) in enumerate(test_loader):\n",
    "    data = data.type(torch.FloatTensor).cuda().unsqueeze(1)\n",
    "    label = label.long().cuda()\n",
    "\n",
    "    outputs = model(data) # get outputs\n",
    "    val_loss = criterion(outputs, label) # get batch loss\n",
    "    tot_val_loss += val_loss.item() # add batch loss to total loss\n",
    "    tot_val_samples += data.shape[0] # add number of samples to total number of samples\n",
    "\n",
    "    # Predictions\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    predictions += list(np.array(predicted.cpu()).ravel())\n",
    "    gt += list(np.array(label.cpu()).ravel())\n",
    "    \n",
    "# Print performance results\n",
    "print('Evaluate on Raw Spectrograms')\n",
    "print(f'precision: {precision_score(gt, predictions, average=\"macro\")}')\n",
    "print(f'recall: {recall_score(gt, predictions, average=\"macro\")}')\n",
    "print(f'f1: {f1_score(gt, predictions, average=\"macro\")}')\n",
    "print(f'acc: {accuracy_score(gt, predictions)}')\n",
    "print()\n",
    "print(classification_report(gt, predictions))\n",
    "print()\n",
    "\n",
    "################################################ EVALUATE ON NOISY RAW SPECT ##############################\n",
    "# Evaluate the model on the test dataset\n",
    "# Load the data (spectrogram)\n",
    "trainset = SpectDataset('../Datasets/train/NoisyRawSpectrograms')\n",
    "valset = SpectDataset('../Datasets/val/NoisyRawSpectrograms')\n",
    "testset = SpectDataset('../Datasets/test/NoisyRawSpectrograms')\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(dataset = trainset,\n",
    "                      batch_size = 32,\n",
    "                      shuffle = True)\n",
    "\n",
    "val_loader = DataLoader(dataset = valset,\n",
    "                      batch_size = 32,\n",
    "                      shuffle = False)\n",
    "\n",
    "test_loader = DataLoader(dataset = testset,\n",
    "                      batch_size = 32,\n",
    "                      shuffle = False)\n",
    "\n",
    "predictions = []\n",
    "gt = []\n",
    "\n",
    "model = AudioNetSpect(num_classes=9)\n",
    "model.load_state_dict(torch.load('models/audio_net_noisy_spect.pt'))\n",
    "model.cuda()\n",
    "\n",
    "model.eval()\n",
    "\n",
    "\n",
    "\n",
    "predictions = []\n",
    "gt = []\n",
    "\n",
    "for i, (label, data, filename) in enumerate(test_loader):\n",
    "    data = data.type(torch.FloatTensor).cuda().unsqueeze(1)\n",
    "    label = label.long().cuda()\n",
    "\n",
    "    outputs = model(data) # get outputs\n",
    "    val_loss = criterion(outputs, label) # get batch loss\n",
    "    tot_val_loss += val_loss.item() # add batch loss to total loss\n",
    "    tot_val_samples += data.shape[0] # add number of samples to total number of samples\n",
    "\n",
    "    # Predictions\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    predictions += list(np.array(predicted.cpu()).ravel())\n",
    "    gt += list(np.array(label.cpu()).ravel())\n",
    "    \n",
    "# Print performance results\n",
    "print('Evaluate on Noisy Raw Spectrograms')\n",
    "print(f'precision: {precision_score(gt, predictions, average=\"macro\")}')\n",
    "print(f'recall: {recall_score(gt, predictions, average=\"macro\")}')\n",
    "print(f'f1: {f1_score(gt, predictions, average=\"macro\")}')\n",
    "print(f'acc: {accuracy_score(gt, predictions)}')\n",
    "print()\n",
    "print(classification_report(gt, predictions))\n",
    "print()\n",
    "\n",
    "################################################ EVALUATE ON NOISY SPECT ##############################\n",
    "# Evaluate the model on the test dataset\n",
    "# Load the data (spectrogram)\n",
    "trainset = SpectDataset('../Datasets/train/NoisySpectrograms')\n",
    "valset = SpectDataset('../Datasets/val/NoisySpectrograms')\n",
    "testset = SpectDataset('../Datasets/test/NoisySpectrograms')\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(dataset = trainset,\n",
    "                      batch_size = 32,\n",
    "                      shuffle = True)\n",
    "\n",
    "val_loader = DataLoader(dataset = valset,\n",
    "                      batch_size = 32,\n",
    "                      shuffle = False)\n",
    "\n",
    "test_loader = DataLoader(dataset = testset,\n",
    "                      batch_size = 32,\n",
    "                      shuffle = False)\n",
    "\n",
    "predictions = []\n",
    "gt = []\n",
    "\n",
    "model = AudioNetSpect(num_classes=9)\n",
    "model.load_state_dict(torch.load('models/audio_net_noisy_spect.pt'))\n",
    "model.cuda()\n",
    "\n",
    "model.eval()\n",
    "\n",
    "\n",
    "\n",
    "predictions = []\n",
    "gt = []\n",
    "\n",
    "for i, (label, data, filename) in enumerate(test_loader):\n",
    "    data = data.type(torch.FloatTensor).cuda().unsqueeze(1)\n",
    "    label = label.long().cuda()\n",
    "\n",
    "    outputs = model(data) # get outputs\n",
    "    val_loss = criterion(outputs, label) # get batch loss\n",
    "    tot_val_loss += val_loss.item() # add batch loss to total loss\n",
    "    tot_val_samples += data.shape[0] # add number of samples to total number of samples\n",
    "\n",
    "    # Predictions\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    predictions += list(np.array(predicted.cpu()).ravel())\n",
    "    gt += list(np.array(label.cpu()).ravel())\n",
    "    \n",
    "# Print performance results\n",
    "print('Evaluate on Noisy Spectrograms')\n",
    "print(f'precision: {precision_score(gt, predictions, average=\"macro\")}')\n",
    "print(f'recall: {recall_score(gt, predictions, average=\"macro\")}')\n",
    "print(f'f1: {f1_score(gt, predictions, average=\"macro\")}')\n",
    "print(f'acc: {accuracy_score(gt, predictions)}')\n",
    "print()\n",
    "print(classification_report(gt, predictions))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try training for 100 Epochs for fair comparison with prune and retrained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Training Loss: 2.006156039842661\n",
      "Val Loss: 4.392049090734319 \n",
      "\n",
      "Epoch 6\n",
      "Training Loss: 0.8998395737962447\n",
      "Val Loss: 3.6370070893115 \n",
      "\n",
      "Epoch 11\n",
      "Training Loss: 0.7574916264966832\n",
      "Val Loss: 5.223125362298046 \n",
      "\n",
      "Epoch 16\n",
      "Training Loss: 0.461643162952817\n",
      "Val Loss: 2.02899823402581 \n",
      "\n",
      "Epoch 21\n",
      "Training Loss: 0.3770394570369651\n",
      "Val Loss: 2.1836482844436946 \n",
      "\n",
      "Epoch 26\n",
      "Training Loss: 0.5138370963758316\n",
      "Val Loss: 4.152632499812171 \n",
      "\n",
      "Epoch 31\n",
      "Training Loss: 0.39495099136146944\n",
      "Val Loss: 2.83058318441592 \n",
      "\n",
      "Epoch 36\n",
      "Training Loss: 0.24477177371095488\n",
      "Val Loss: 2.122712532463281 \n",
      "\n",
      "Epoch 41\n",
      "Training Loss: 0.6040730413751326\n",
      "Val Loss: 2.779883631221626 \n",
      "\n",
      "Epoch 46\n",
      "Training Loss: 0.22652367899275344\n",
      "Val Loss: 2.576101123071883 \n",
      "\n",
      "Epoch 51\n",
      "Training Loss: 0.5578013806995274\n",
      "Val Loss: 2.085878755978268 \n",
      "\n",
      "Epoch 56\n",
      "Training Loss: 0.34497254798053834\n",
      "Val Loss: 1.7634211011109469 \n",
      "\n",
      "Epoch 61\n",
      "Training Loss: 0.21479932074367403\n",
      "Val Loss: 2.8806695084532965 \n",
      "\n",
      "Epoch 66\n",
      "Training Loss: 0.16350214592977494\n",
      "Val Loss: 3.058414125693557 \n",
      "\n",
      "Epoch 71\n",
      "Training Loss: 0.21549580845495928\n",
      "Val Loss: 3.142665652074831 \n",
      "\n",
      "Epoch 76\n",
      "Training Loss: 0.5107167325475239\n",
      "Val Loss: 9.077649954324315 \n",
      "\n",
      "Epoch 81\n",
      "Training Loss: 0.17130597054526425\n",
      "Val Loss: 3.611000067059649 \n",
      "\n",
      "Epoch 86\n",
      "Training Loss: 0.35450571718747204\n",
      "Val Loss: 3.5784286379652177 \n",
      "\n",
      "Epoch 91\n",
      "Training Loss: 0.19937569667936128\n",
      "Val Loss: 5.220648714968854 \n",
      "\n",
      "Epoch 96\n",
      "Training Loss: 0.15318249400529632\n",
      "Val Loss: 2.4753260876497496 \n",
      "\n",
      "Epoch 100\n",
      "Training Loss: 0.1586383148231476\n",
      "Val Loss: 1.8373431941980254 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the data (spectrogram)\n",
    "trainset = SpectDataset('../Datasets/train/Spectrograms')\n",
    "valset = SpectDataset('../Datasets/val/Spectrograms')\n",
    "testset = SpectDataset('../Datasets/test/Spectrograms')\n",
    "\n",
    "# Load model\n",
    "model = AudioNetSpect(num_classes=9)\n",
    "model.cuda()\n",
    "\n",
    "# Get loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "# Create data loaders\n",
    "val_loader = DataLoader(dataset = valset,\n",
    "                      batch_size = 32,\n",
    "                      shuffle = False)\n",
    "\n",
    "train_loader = DataLoader(dataset = trainset,\n",
    "                      batch_size = 32,\n",
    "                      shuffle = True)\n",
    "\n",
    "test_loader = DataLoader(dataset = testset,\n",
    "                      batch_size = 32,\n",
    "                      shuffle = True)\n",
    "\n",
    "# Train the model\n",
    "best_val_loss = math.inf\n",
    "num_epochs = 100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    tot_train_loss = 0\n",
    "    tot_train_samples = 0\n",
    "    \n",
    "    # Train Loop\n",
    "    model.train()\n",
    "    for i, (label, data, filename) in enumerate(train_loader):\n",
    "        data = data.type(torch.FloatTensor).cuda().unsqueeze(1)\n",
    "        label = label.long().cuda()\n",
    "        \n",
    "        optimizer.zero_grad() # clear gradients\n",
    "        outputs = model(data) # get outputs\n",
    "        train_loss = criterion(outputs, label) # get batch loss\n",
    "        tot_train_loss += train_loss.item() # add batch loss to total loss\n",
    "        tot_train_samples += data.shape[0] # add number of samples to total number of samples\n",
    "        train_loss.backward() # get gradients\n",
    "        optimizer.step() # update parameters\n",
    "    avg_train_loss = tot_train_loss / len(train_loader)\n",
    "    \n",
    "    # Eval Loop\n",
    "    tot_val_loss = 0\n",
    "    tot_val_samples = 0\n",
    "    pred_vec = []\n",
    "    label_vec = []\n",
    "    \n",
    "    model.eval()\n",
    "    for i, (label, data, filename) in enumerate(val_loader):\n",
    "        data = data.type(torch.FloatTensor).cuda().unsqueeze(1)\n",
    "        label = label.long().cuda()\n",
    "        \n",
    "        outputs = model(data) # get outputs\n",
    "        val_loss = criterion(outputs, label) # get batch loss\n",
    "        tot_val_loss += val_loss.item() # add batch loss to total loss\n",
    "        tot_val_samples += data.shape[0] # add number of samples to total number of samples\n",
    "\n",
    "    avg_val_loss = tot_val_loss / len(val_loader)\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        torch.save(model.state_dict(), 'models/audio_net_spect_100epoch.pt')\n",
    "        \n",
    "    # print losses every 5 epochs\n",
    "    if (epoch + 1) % 5 == 1 or (epoch + 1) == num_epochs:\n",
    "        print('Epoch {}'.format(epoch + 1))\n",
    "        print('Training Loss: {}'.format(avg_train_loss))\n",
    "        print('Val Loss: {} \\n'.format(avg_val_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate 100epoch trained spect model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate on Raw Spectrograms\n",
      "precision: 0.768389362301778\n",
      "recall: 0.6563937956901786\n",
      "f1: 0.6633992651070547\n",
      "acc: 0.6326949384404925\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.80       170\n",
      "           1       0.82      0.63      0.71       162\n",
      "           2       0.38      0.94      0.54       202\n",
      "           3       1.00      0.41      0.58       179\n",
      "           4       0.75      0.50      0.60       203\n",
      "           5       0.56      0.76      0.64       184\n",
      "           6       0.80      0.59      0.68       119\n",
      "           7       0.96      0.37      0.53       204\n",
      "           8       0.85      0.90      0.88        39\n",
      "\n",
      "    accuracy                           0.63      1462\n",
      "   macro avg       0.77      0.66      0.66      1462\n",
      "weighted avg       0.75      0.63      0.64      1462\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the data (spectrogram)\n",
    "trainset = SpectDataset('../Datasets/train/Spectrograms')\n",
    "valset = SpectDataset('../Datasets/val/Spectrograms')\n",
    "testset = SpectDataset('../Datasets/test/Spectrograms')\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(dataset = trainset,\n",
    "                      batch_size = 32,\n",
    "                      shuffle = True)\n",
    "\n",
    "val_loader = DataLoader(dataset = valset,\n",
    "                      batch_size = 32,\n",
    "                      shuffle = False)\n",
    "\n",
    "test_loader = DataLoader(dataset = testset,\n",
    "                      batch_size = 32,\n",
    "                      shuffle = False)\n",
    "\n",
    "predictions = []\n",
    "gt = []\n",
    "\n",
    "model = AudioNetSpect(num_classes=9)\n",
    "model.load_state_dict(torch.load('models/audio_net_spect_100epoch.pt'))\n",
    "model.cuda()\n",
    "\n",
    "model.eval()\n",
    "\n",
    "\n",
    "\n",
    "predictions = []\n",
    "gt = []\n",
    "\n",
    "for i, (label, data, filename) in enumerate(test_loader):\n",
    "    data = data.type(torch.FloatTensor).cuda().unsqueeze(1)\n",
    "    label = label.long().cuda()\n",
    "\n",
    "    outputs = model(data) # get outputs\n",
    "    val_loss = criterion(outputs, label) # get batch loss\n",
    "    tot_val_loss += val_loss.item() # add batch loss to total loss\n",
    "    tot_val_samples += data.shape[0] # add number of samples to total number of samples\n",
    "\n",
    "    # Predictions\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    predictions += list(np.array(predicted.cpu()).ravel())\n",
    "    gt += list(np.array(label.cpu()).ravel())\n",
    "    \n",
    "# Print performance results\n",
    "print('Evaluate on Raw Spectrograms')\n",
    "print(f'precision: {precision_score(gt, predictions, average=\"macro\")}')\n",
    "print(f'recall: {recall_score(gt, predictions, average=\"macro\")}')\n",
    "print(f'f1: {f1_score(gt, predictions, average=\"macro\")}')\n",
    "print(f'acc: {accuracy_score(gt, predictions)}')\n",
    "print()\n",
    "print(classification_report(gt, predictions))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Everything below is scratch work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nlp]",
   "language": "python",
   "name": "conda-env-nlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
