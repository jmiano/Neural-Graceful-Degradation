{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, random_split, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import scipy.io\n",
    "from scipy.signal import spectrogram\n",
    "import os\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "import math\n",
    "from librosa.feature import melspectrogram\n",
    "from librosa.display import specshow\n",
    "import cv2\n",
    "import random\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, accuracy_score, classification_report\n",
    "import torch.nn.utils.prune as prune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get spect_dataset\n",
    "class SpectDataset(Dataset):\n",
    "    def __init__(self, data_dir):\n",
    "        self.sample_list = []\n",
    "        \n",
    "        for filename in os.listdir(data_dir):\n",
    "            image = plt.imread(f'{data_dir}/{filename}')[:,:,0]\n",
    "            label = int(filename.split('-')[0][-1])\n",
    "            self.sample_list.append((label, torch.tensor(image), filename)) #class_label, data, filename\n",
    "                \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sample_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.sample_list[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data (spectrogram)\n",
    "trainset = SpectDataset('../Datasets/train/Spectrograms')\n",
    "valset = SpectDataset('../Datasets/val/Spectrograms')\n",
    "testset = SpectDataset('../Datasets/test/Spectrograms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Neural Network Model \n",
    "class AudioNetSpect(nn.Module):  #2D convolutions on spectrograms\n",
    "    def __init__(self, num_classes):\n",
    "        super(AudioNetSpect, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=7, stride=1, padding=0) #try making kernels larger, fewer layers, less maxp\n",
    "        self.batchnorm1 = nn.BatchNorm2d(16)\n",
    "        self.drop1 = nn.Dropout(p=0.5)\n",
    "        self.lrelu1 = nn.LeakyReLU()\n",
    "        self.max1 = nn.MaxPool2d(kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=0)\n",
    "        self.batchnorm2 = nn.BatchNorm2d(32)\n",
    "        self.drop2 = nn.Dropout(p=0.5)\n",
    "        self.lrelu2 = nn.LeakyReLU()\n",
    "        self.max2 = nn.MaxPool2d(kernel_size=3)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=0)\n",
    "        self.batchnorm3 = nn.BatchNorm2d(64)\n",
    "        self.fc1 = nn.Linear(64 * 8 * 13, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #print(x.shape)\n",
    "        x = self.conv1(x)\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.drop1(x)\n",
    "        x = self.lrelu1(x)\n",
    "        x = self.max1(x)\n",
    "        #print(x.shape)\n",
    "        x = self.conv2(x)\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.drop2(x)\n",
    "        x = self.lrelu2(x)\n",
    "        #print(x.shape)\n",
    "        x = self.max2(x)\n",
    "        #print(x.shape)\n",
    "        x = self.conv3(x)\n",
    "        x = self.batchnorm3(x)\n",
    "        #print(x.shape)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        #print(x.shape)\n",
    "        x = self.fc1(x)\n",
    "        #print(x.shape)\n",
    "        out = self.fc2(x)\n",
    "        #print(out.shape)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AudioNetSpect(\n",
       "  (conv1): Conv2d(1, 16, kernel_size=(7, 7), stride=(1, 1))\n",
       "  (batchnorm1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (drop1): Dropout(p=0.5, inplace=False)\n",
       "  (lrelu1): LeakyReLU(negative_slope=0.01)\n",
       "  (max1): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (batchnorm2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (drop2): Dropout(p=0.5, inplace=False)\n",
       "  (lrelu2): LeakyReLU(negative_slope=0.01)\n",
       "  (max2): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv3): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (batchnorm3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc1): Linear(in_features=6656, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=9, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model\n",
    "model = AudioNetSpect(num_classes=9)\n",
    "model.load_state_dict(torch.load('models/audio_net_spect.pt'))\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import Iterable\n",
    "\n",
    "def get_prunable_modules(model):\n",
    "    modules = nn.Sequential(*list(model.children()))\n",
    "    print(modules)\n",
    "\n",
    "    # print(modules)\n",
    "    parameters_to_prune = (\n",
    "        (modules[0], 'weight'),\n",
    "        (modules[5], 'weight'),\n",
    "        (modules[10], 'weight')\n",
    "        )\n",
    "\n",
    "    modules_pruned = (\n",
    "        (modules[0]),\n",
    "        (modules[5]),\n",
    "        (modules[10])\n",
    "        )\n",
    "\n",
    "    return parameters_to_prune, modules_pruned\n",
    "\n",
    "def do_pruning(pruned_model, value = 0.35):\n",
    "    parameters_to_prune, modules_to_prune = get_prunable_modules(model)\n",
    "    print(parameters_to_prune)\n",
    "\n",
    "    prune.global_unstructured(\n",
    "        parameters_to_prune,\n",
    "        pruning_method=prune.L1Unstructured,\n",
    "        amount=value)\n",
    "\n",
    "    for m in modules_to_prune:\n",
    "        prune.remove(m, 'weight')\n",
    "\n",
    "    return pruned_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(1, 16, kernel_size=(7, 7), stride=(1, 1))\n",
      "  (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): Dropout(p=0.5, inplace=False)\n",
      "  (3): LeakyReLU(negative_slope=0.01)\n",
      "  (4): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "  (5): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (6): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (7): Dropout(p=0.5, inplace=False)\n",
      "  (8): LeakyReLU(negative_slope=0.01)\n",
      "  (9): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "  (10): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (11): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (12): Linear(in_features=6656, out_features=128, bias=True)\n",
      "  (13): Linear(in_features=128, out_features=9, bias=True)\n",
      ")\n",
      "((Conv2d(1, 16, kernel_size=(7, 7), stride=(1, 1)), 'weight'), (Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1)), 'weight'), (Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1)), 'weight'))\n"
     ]
    }
   ],
   "source": [
    "prune_percentage = 0.35\n",
    "pruned_model = model\n",
    "\n",
    "pruned_model = do_pruning(pruned_model, prune_percentage)\n",
    "torch.save(pruned_model.state_dict(), 'models/pruned_audio_net_spect.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Pruned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.765887648474086\n",
      "recall: 0.6187144662593559\n",
      "f1: 0.6381678339888097\n",
      "acc: 0.6374829001367989\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.52      0.68       170\n",
      "           1       0.40      0.90      0.55       162\n",
      "           2       0.58      0.83      0.69       202\n",
      "           3       0.94      0.36      0.52       179\n",
      "           4       0.61      0.66      0.63       203\n",
      "           5       0.64      0.74      0.69       184\n",
      "           6       0.83      0.50      0.62       119\n",
      "           7       0.93      0.58      0.72       204\n",
      "           8       1.00      0.49      0.66        39\n",
      "\n",
      "    accuracy                           0.64      1462\n",
      "   macro avg       0.77      0.62      0.64      1462\n",
      "weighted avg       0.74      0.64      0.64      1462\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test dataset\n",
    "# Load the data (spectrogram)\n",
    "trainset = SpectDataset('../Datasets/train/Spectrograms')\n",
    "valset = SpectDataset('../Datasets/val/Spectrograms')\n",
    "testset = SpectDataset('../Datasets/test/Spectrograms')\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(dataset = trainset,\n",
    "                      batch_size = 32,\n",
    "                      shuffle = True)\n",
    "\n",
    "val_loader = DataLoader(dataset = valset,\n",
    "                      batch_size = 32,\n",
    "                      shuffle = False)\n",
    "\n",
    "test_loader = DataLoader(dataset = testset,\n",
    "                      batch_size = 32,\n",
    "                      shuffle = False)\n",
    "\n",
    "predictions = []\n",
    "gt = []\n",
    "\n",
    "model = AudioNetSpect(num_classes=9)\n",
    "model.load_state_dict(torch.load('models/pruned_audio_net_spect.pt'))\n",
    "model.cuda()\n",
    "\n",
    "model.eval()\n",
    "\n",
    "\n",
    "\n",
    "predictions = []\n",
    "gt = []\n",
    "\n",
    "for i, (label, data, filename) in enumerate(test_loader):\n",
    "    data = data.type(torch.FloatTensor).cuda().unsqueeze(1)\n",
    "    label = label.long().cuda()\n",
    "\n",
    "    outputs = model(data) # get outputs\n",
    "\n",
    "    # Predictions\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    predictions += list(np.array(predicted.cpu()).ravel())\n",
    "    gt += list(np.array(label.cpu()).ravel())\n",
    "    \n",
    "# Print performance results\n",
    "print(f'precision: {precision_score(gt, predictions, average=\"macro\")}')\n",
    "print(f'recall: {recall_score(gt, predictions, average=\"macro\")}')\n",
    "print(f'f1: {f1_score(gt, predictions, average=\"macro\")}')\n",
    "print(f'acc: {accuracy_score(gt, predictions)}')\n",
    "print()\n",
    "print(classification_report(gt, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrain Pruned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Training Loss: 0.49400416572672734\n",
      "Val Loss: 1.8222012539272723 \n",
      "\n",
      "Epoch 6\n",
      "Training Loss: 0.5490526497984926\n",
      "Val Loss: 2.8393055799609535 \n",
      "\n",
      "Epoch 11\n",
      "Training Loss: 0.3650395260124967\n",
      "Val Loss: 2.4020306514272387 \n",
      "\n",
      "Epoch 16\n",
      "Training Loss: 0.223817454610664\n",
      "Val Loss: 1.4553745991509894 \n",
      "\n",
      "Epoch 21\n",
      "Training Loss: 0.25075326082499133\n",
      "Val Loss: 1.6434339783761813 \n",
      "\n",
      "Epoch 26\n",
      "Training Loss: 0.20384872219849215\n",
      "Val Loss: 1.3925489543572716 \n",
      "\n",
      "Epoch 31\n",
      "Training Loss: 0.35777548047295515\n",
      "Val Loss: 1.592189267196733 \n",
      "\n",
      "Epoch 36\n",
      "Training Loss: 0.23417536537770098\n",
      "Val Loss: 1.4877949379303532 \n",
      "\n",
      "Epoch 41\n",
      "Training Loss: 0.2977689635143548\n",
      "Val Loss: 1.7477763474250778 \n",
      "\n",
      "Epoch 46\n",
      "Training Loss: 0.18233761492360637\n",
      "Val Loss: 1.5056956456771686 \n",
      "\n",
      "Epoch 50\n",
      "Training Loss: 0.790597375711777\n",
      "Val Loss: 5.79589884523296 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the data (spectrogram)\n",
    "trainset = SpectDataset('../Datasets/train/Spectrograms')\n",
    "valset = SpectDataset('../Datasets/val/Spectrograms')\n",
    "testset = SpectDataset('../Datasets/test/Spectrograms')\n",
    "\n",
    "# Load the pruned model\n",
    "model = AudioNetSpect(num_classes=9)\n",
    "model.load_state_dict(torch.load('models/pruned_audio_net_spect.pt'))\n",
    "model.cuda()\n",
    "\n",
    "# Get loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "# Create data loaders\n",
    "val_loader = DataLoader(dataset = valset,\n",
    "                      batch_size = 32,\n",
    "                      shuffle = False)\n",
    "\n",
    "train_loader = DataLoader(dataset = trainset,\n",
    "                      batch_size = 32,\n",
    "                      shuffle = True)\n",
    "\n",
    "test_loader = DataLoader(dataset = testset,\n",
    "                      batch_size = 32,\n",
    "                      shuffle = True)\n",
    "\n",
    "# Train the model\n",
    "best_val_loss = math.inf\n",
    "num_epochs = 50\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    tot_train_loss = 0\n",
    "    tot_train_samples = 0\n",
    "    \n",
    "    # Train Loop\n",
    "    model.train()\n",
    "    for i, (label, data, filename) in enumerate(train_loader):\n",
    "        data = data.type(torch.FloatTensor).cuda().unsqueeze(1)\n",
    "        label = label.long().cuda()\n",
    "        \n",
    "        optimizer.zero_grad() # clear gradients\n",
    "        outputs = model(data) # get outputs\n",
    "        train_loss = criterion(outputs, label) # get batch loss\n",
    "        tot_train_loss += train_loss.item() # add batch loss to total loss\n",
    "        tot_train_samples += data.shape[0] # add number of samples to total number of samples\n",
    "        train_loss.backward() # get gradients\n",
    "        optimizer.step() # update parameters\n",
    "    avg_train_loss = tot_train_loss / len(train_loader)\n",
    "    \n",
    "    # Eval Loop\n",
    "    tot_val_loss = 0\n",
    "    tot_val_samples = 0\n",
    "    pred_vec = []\n",
    "    label_vec = []\n",
    "    \n",
    "    model.eval()\n",
    "    for i, (label, data, filename) in enumerate(val_loader):\n",
    "        data = data.type(torch.FloatTensor).cuda().unsqueeze(1)\n",
    "        label = label.long().cuda()\n",
    "        \n",
    "        outputs = model(data) # get outputs\n",
    "        val_loss = criterion(outputs, label) # get batch loss\n",
    "        tot_val_loss += val_loss.item() # add batch loss to total loss\n",
    "        tot_val_samples += data.shape[0] # add number of samples to total number of samples\n",
    "        \n",
    "    avg_val_loss = tot_val_loss / len(val_loader)\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        torch.save(model.state_dict(), 'models/pruned_audio_net_spect_retrained.pt')\n",
    "        \n",
    "    # print losses every 5 epochs\n",
    "    if (epoch + 1) % 5 == 1 or (epoch + 1) == num_epochs:\n",
    "        print('Epoch {}'.format(epoch + 1))\n",
    "        print('Training Loss: {}'.format(avg_train_loss))\n",
    "        print('Val Loss: {} \\n'.format(avg_val_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.7196189941106613\n",
      "recall: 0.7164806746565913\n",
      "f1: 0.6950046780627795\n",
      "acc: 0.6976744186046512\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.70      0.79       170\n",
      "           1       0.90      0.68      0.77       162\n",
      "           2       0.54      0.89      0.67       202\n",
      "           3       0.82      0.65      0.73       179\n",
      "           4       0.73      0.33      0.45       203\n",
      "           5       0.64      0.77      0.70       184\n",
      "           6       0.63      0.72      0.67       119\n",
      "           7       0.74      0.82      0.78       204\n",
      "           8       0.56      0.90      0.69        39\n",
      "\n",
      "    accuracy                           0.70      1462\n",
      "   macro avg       0.72      0.72      0.70      1462\n",
      "weighted avg       0.73      0.70      0.69      1462\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test dataset\n",
    "# Load the data (spectrogram)\n",
    "trainset = SpectDataset('../Datasets/train/Spectrograms')\n",
    "valset = SpectDataset('../Datasets/val/Spectrograms')\n",
    "testset = SpectDataset('../Datasets/test/Spectrograms')\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(dataset = trainset,\n",
    "                      batch_size = 32,\n",
    "                      shuffle = True)\n",
    "\n",
    "val_loader = DataLoader(dataset = valset,\n",
    "                      batch_size = 32,\n",
    "                      shuffle = False)\n",
    "\n",
    "test_loader = DataLoader(dataset = testset,\n",
    "                      batch_size = 32,\n",
    "                      shuffle = False)\n",
    "\n",
    "predictions = []\n",
    "gt = []\n",
    "\n",
    "model = AudioNetSpect(num_classes=9)\n",
    "model.load_state_dict(torch.load('models/pruned_audio_net_spect_retrained.pt'))\n",
    "model.cuda()\n",
    "\n",
    "model.eval()\n",
    "\n",
    "\n",
    "\n",
    "predictions = []\n",
    "gt = []\n",
    "\n",
    "for i, (label, data, filename) in enumerate(test_loader):\n",
    "    data = data.type(torch.FloatTensor).cuda().unsqueeze(1)\n",
    "    label = label.long().cuda()\n",
    "\n",
    "    outputs = model(data) # get outputs\n",
    "    val_loss = criterion(outputs, label) # get batch loss\n",
    "    tot_val_loss += val_loss.item() # add batch loss to total loss\n",
    "    tot_val_samples += data.shape[0] # add number of samples to total number of samples\n",
    "\n",
    "    # Predictions\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    predictions += list(np.array(predicted.cpu()).ravel())\n",
    "    gt += list(np.array(label.cpu()).ravel())\n",
    "    \n",
    "# Print performance results\n",
    "print(f'precision: {precision_score(gt, predictions, average=\"macro\")}')\n",
    "print(f'recall: {recall_score(gt, predictions, average=\"macro\")}')\n",
    "print(f'f1: {f1_score(gt, predictions, average=\"macro\")}')\n",
    "print(f'acc: {accuracy_score(gt, predictions)}')\n",
    "print()\n",
    "print(classification_report(gt, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Everything below is scratch work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nlp]",
   "language": "python",
   "name": "conda-env-nlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
